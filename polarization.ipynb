{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7cadbb41-e934-4859-9d8a-f46b51a7dd3c",
      "metadata": {
        "id": "7cadbb41-e934-4859-9d8a-f46b51a7dd3c"
      },
      "source": [
        "## CNN Modeling of CMB Foregrounds\n",
        "The goal of this project is to use a Convolutional Neural Network (CNN) to predict the foreground contamination of a Cosmic Microwave Background (CMB) map. The training data will be maps of foreground models created using the Python Sky Model (PySM3). The training data will consist of maps of multiple frequency bands and both Q and U polarization modes and the Temperature mode to make up input channels. The training data will be found by randomly(?) selecting a region on an all-sky map, and convoluting together pixels in the selected region and across the frequency/polarization channels. After the model is trained, it will be fed a contaminated CMB map and attempt to get rid of the present foregrounds."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "152bea32-a8d0-4f1b-839c-575fb23c3537",
      "metadata": {
        "id": "152bea32-a8d0-4f1b-839c-575fb23c3537"
      },
      "source": [
        "# Set Device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "a20c4e5a-f91d-4b71-96e6-54b73cfd3f67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a20c4e5a-f91d-4b71-96e6-54b73cfd3f67",
        "outputId": "071568fb-c7fd-464f-9c4d-41c1777a90b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "\n",
            "Google Drive mounted\n",
            "\n",
            "/content/gdrive/MyDrive/ML\n",
            "/content\n",
            "\t1. uninstall mlinphysics\n",
            "\t2. sparse clone mlinphysics\n",
            "\n",
            "/content/mlinphysics\n",
            "\n",
            "\t3. install mlinphysics\n",
            "\n",
            "/content\n",
            "/content/gdrive/MyDrive/ML/Foregrounds\n"
          ]
        }
      ],
      "source": [
        "COLAB_FOLDER = 'ML' # change as needed\n",
        "GITHUB_USER  = 'hbprosper'\n",
        "GITHUB_REPO  = 'mlinphysics'\n",
        "GITHUB_FOLDERS = ['mlinphysics']\n",
        "#------------------------------------------------------\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    print('\\nGoogle Drive mounted\\n')\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    print('\\nRunning locally\\n')\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    MYDRIVE     = '/content/gdrive/MyDrive'\n",
        "    GITHUB_BASE = 'https://raw.githubusercontent.com'\n",
        "    MAIN        = 'refs/heads/main'\n",
        "    GITHUB_PATH = f'{MYDRIVE}/{COLAB_FOLDER}'\n",
        "    #------------------------------------------------------\n",
        "    %cd {GITHUB_PATH}\n",
        "    %rm -f {GITHUB_PATH}/clone2colab.ipynb\n",
        "    !wget -q {GITHUB_BASE}/{GITHUB_USER}/{GITHUB_REPO}/{MAIN}/clone2colab.ipynb\n",
        "    %run {GITHUB_PATH}/clone2colab.ipynb\n",
        "    %cd /content/gdrive/MyDrive/ML/Foregrounds/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c116d31-63ec-4f03-b7d8-f13bfbd62f3b",
      "metadata": {
        "id": "7c116d31-63ec-4f03-b7d8-f13bfbd62f3b"
      },
      "source": [
        "# Image Creation\n",
        "The CNN will be trained on square images of all sky projections from the Python Sky Model. These images will have 9 input channels, 3 for polarization (I,Q,U) and 3 for frequency (100 GHz, 217 GHz, 353 GHz)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "ae376711-7786-492f-9264-a7423a0357ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae376711-7786-492f-9264-a7423a0357ef",
        "outputId": "5c731a67-08f4-41aa-e3fd-5b222f9af009"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pysm3 in /usr/local/lib/python3.12/dist-packages (3.4.3)\n",
            "Requirement already satisfied: astropy in /usr/local/lib/python3.12/dist-packages (from pysm3) (7.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from pysm3) (3.15.1)\n",
            "Requirement already satisfied: healpy>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from pysm3) (1.18.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from pysm3) (0.60.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.12/dist-packages (from pysm3) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.15 in /usr/local/lib/python3.12/dist-packages (from pysm3) (1.14.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.12/dist-packages (from pysm3) (0.10.2)\n",
            "Requirement already satisfied: pyerfa>=2.0.1.1 in /usr/local/lib/python3.12/dist-packages (from astropy->pysm3) (2.0.1.5)\n",
            "Requirement already satisfied: astropy-iers-data>=0.2025.9.29.0.35.48 in /usr/local/lib/python3.12/dist-packages (from astropy->pysm3) (0.2025.11.10.0.38.31)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from astropy->pysm3) (6.0.3)\n",
            "Requirement already satisfied: packaging>=22.0.0 in /usr/local/lib/python3.12/dist-packages (from astropy->pysm3) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->pysm3) (0.43.0)\n",
            "Requirement already satisfied: healpy in /usr/local/lib/python3.12/dist-packages (1.18.1)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.12/dist-packages (from healpy) (1.26.4)\n",
            "Requirement already satisfied: astropy in /usr/local/lib/python3.12/dist-packages (from healpy) (7.1.1)\n",
            "Requirement already satisfied: pyerfa>=2.0.1.1 in /usr/local/lib/python3.12/dist-packages (from astropy->healpy) (2.0.1.5)\n",
            "Requirement already satisfied: astropy-iers-data>=0.2025.9.29.0.35.48 in /usr/local/lib/python3.12/dist-packages (from astropy->healpy) (0.2025.11.10.0.38.31)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from astropy->healpy) (6.0.3)\n",
            "Requirement already satisfied: packaging>=22.0.0 in /usr/local/lib/python3.12/dist-packages (from astropy->healpy) (25.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pysm3\n",
        "!pip install healpy\n",
        "import pysm3\n",
        "import pysm3.units as u\n",
        "import healpy as hp\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import torch\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#function to write the all sky maps with and without contaminants to fits file\n",
        "def make_foreground_maps(frequencies, strings, nside):\n",
        "    sky = pysm3.Sky(nside = nside, preset_strings=strings + [\"c1\"])\n",
        "    sky_true = pysm3.Sky(nside = nside, preset_strings = [\"c1\"])\n",
        "    for frequency in frequencies:\n",
        "        skymap = sky.get_emission(frequency*u.GHz)\n",
        "        skymap = skymap.to(u.uK_CMB, equivalencies=u.cmb_equivalencies(frequency*u.GHz))\n",
        "        skymap_true = sky_true.get_emission(frequency*u.GHz)\n",
        "        skymap_true = skymap_true.to(u.uK_CMB, equivalencies=u.cmb_equivalencies(frequency*u.GHz))\n",
        "        hp.fitsfunc.write_map(str(frequency) + \"GHz\", skymap, overwrite=True)\n",
        "        hp.fitsfunc.write_map(str(frequency) + \"GHz_true\", skymap_true, overwrite=True)\n",
        "\n",
        "#function to write all sky lat/lon maps to fits file\n",
        "def make_angle_maps(nside):\n",
        "    npix = hp.nside2npix(nside)\n",
        "    arr = np.arange(npix)\n",
        "    m = hp.pixelfunc.pix2ang(nside,arr)\n",
        "    hp.fitsfunc.write_map(str(nside) + \"_lat\", m[0], overwrite=True)\n",
        "    hp.fitsfunc.write_map(str(nside) + \"_lon\", m[1], overwrite=True)\n",
        "\n",
        "\n",
        "def make_images(num, res):\n",
        "    #This function randomly selects a patch on the sky to create images for model.\n",
        "    #Generate the CMB image and the lat/lon images on the sky\n",
        "    #num is the number of images\n",
        "    #res is the resolution of the image in arcminutes\n",
        "\n",
        "    #loading all sky projections\n",
        "    map_100 = hp.fitsfunc.read_map(\"100GHz\", field = (0,1,2))\n",
        "    map_100_true = hp.fitsfunc.read_map(\"100GHz_true\", field = (0,1,2))\n",
        "    lat_map = hp.fitsfunc.read_map(\"512_lat\", field = 0)\n",
        "    lon_map = hp.fitsfunc.read_map(\"512_lon\", field = 0)\n",
        "\n",
        "\n",
        "    size = 128\n",
        "    image_arr = np.zeros((num, 4, size, size))\n",
        "\n",
        "    for i in range(num):\n",
        "        #random generation of lat lon angles on sky\n",
        "        print(\"generating image \" + str(i))\n",
        "        lon = np.random.random() * 360\n",
        "        lat = np.random.random() * 180 - 90\n",
        "\n",
        "\n",
        "        #generate Q map for both contaminated and uncontaminated skies\n",
        "        Q_100_square = hp.gnomview(map_100[1], rot = [lon, lat], reso = res, xsize = size, return_projected_map=True, no_plot=True)\n",
        "        plt.close('all')\n",
        "        Q_100_true = hp.gnomview(map_100_true[1], rot = [lon, lat], reso = res, xsize = size, return_projected_map=True, no_plot=True)\n",
        "\n",
        "        #generate lat/lon maps\n",
        "        lon_square = hp.gnomview(lon_map, rot=[lon,lat], reso=res, xsize=size, return_projected_map=True, no_plot=True)\n",
        "        lat_square = hp.gnomview(lat_map, rot=[lon,lat], reso=res, xsize=size, return_projected_map=True, no_plot=True)\n",
        "\n",
        "        #stack the maps into one 3D array along first axis\n",
        "        image_arr[i] = np.stack((Q_100_square, Q_100_true, lat_square, lon_square))\n",
        "\n",
        "    #save array to h5 file\n",
        "    with h5py.File('images.h5', 'w') as hf:\n",
        "        hf.create_dataset('foregrounds_images', data = image_arr)\n",
        "\n",
        "#generate all sky projections and cuts. This only has to be done once, then can be commented out unless new foreground contaminants or cuts are desired.\n",
        "#make_foreground_maps([100,217,353], [\"s1\", \"d1\"], 512)\n",
        "#make_angle_maps(512)\n",
        "#make_images(2000, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "8defc580-7586-4c63-8fcb-6fea706fe29d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8defc580-7586-4c63-8fcb-6fea706fe29d",
        "outputId": "6d797215-cd50-41ce-c6cb-83f3749dc940"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\tAvailable device: cuda\n",
            "\n"
          ]
        }
      ],
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'\\n\\tAvailable device: {str(DEVICE):4s}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4682ab0f-748c-4ccf-bff1-3432c775c42e",
      "metadata": {
        "id": "4682ab0f-748c-4ccf-bff1-3432c775c42e"
      },
      "source": [
        "# Convolutional Neural Network Layout\n",
        "The input shape of the image fed to the network is (9,200,200). The output shape should be (3,200,200) with just Temperature mode output. Going to try a simple 3 level model going to (27, 200, 200) before final step back to (3, 200, 200)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "672f6c36-886c-4119-a410-6e3ee749ee15",
      "metadata": {
        "id": "672f6c36-886c-4119-a410-6e3ee749ee15"
      },
      "source": [
        "# Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "f823bf52-4786-4e96-aaa2-20ea118e660a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f823bf52-4786-4e96-aaa2-20ea118e660a",
        "outputId": "212a2015-f878-40cc-ba87-924a68ab6e35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name: foregrounds\n",
            "file:\n",
            "  losses: runs/2025-11-25_1622/foregrounds_losses.csv\n",
            "  params: runs/2025-11-25_1622/foregrounds_params.pth\n",
            "  init_params: runs/2025-11-25_1622/foregrounds_init_params.pth\n",
            "  plots: runs/2025-11-25_1622/foregrounds_plots.png\n",
            "batch_size: 16\n",
            "train_size: 384\n",
            "test_size: 25\n",
            "val_size: 1591\n",
            "monitor_step: 10\n",
            "delete: true\n",
            "frac: 0.015\n",
            "n_epochs: 4000\n",
            "n_iters_per_epoch: 24\n",
            "n_iterations: 96000\n",
            "n_steps: 4\n",
            "n_iters_per_step: 24000\n",
            "base_lr: 0.001\n",
            "gamma: 0.8\n",
            "\n",
            "384 25 1591\n"
          ]
        }
      ],
      "source": [
        "import mlinphysics.nn as mlp\n",
        "import mlinphysics.utils.data as dat\n",
        "import mlinphysics.utils.monitor as mon\n",
        "\n",
        "#load images\n",
        "\n",
        "with h5py.File(\"images.h5\", \"r\") as f:\n",
        "    images = f['foregrounds_images']\n",
        "    images = images[...]\n",
        "\n",
        "#configure model\n",
        "\n",
        "    name = 'foregrounds'\n",
        "\n",
        "    load_existing_config = False\n",
        "\n",
        "    if load_existing_config:\n",
        "        config = mlp.Config(f'{name}.yaml')\n",
        "    else:\n",
        "        config = mlp.Config(name)\n",
        "\n",
        "        #training config\n",
        "        n_images = 2000\n",
        "        batch_size = 16\n",
        "        n_iters_per_epoch = 24\n",
        "        train_size = n_iters_per_epoch * batch_size\n",
        "        test_size = 25\n",
        "        val_size = n_images - train_size - test_size\n",
        "\n",
        "        config('batch_size', batch_size)\n",
        "        config('train_size', train_size)\n",
        "        config('test_size', test_size)\n",
        "        config('val_size', val_size)\n",
        "\n",
        "        config('monitor_step', 10)\n",
        "        config('delete', True)\n",
        "        config('frac', 0.015)\n",
        "\n",
        "        #optimizer/scheduler\n",
        "\n",
        "        config('n_epochs', 4000)\n",
        "        config('n_iters_per_epoch', n_iters_per_epoch)\n",
        "        config('n_iterations', config('n_epochs') * config('n_iters_per_epoch'))\n",
        "        config('n_steps', 4)\n",
        "        config('n_iters_per_step', config('n_iterations') // config('n_steps'))\n",
        "        config('base_lr', 1.e-3)\n",
        "        config('gamma', 0.8)\n",
        "\n",
        "        config.save()\n",
        "    print(config)\n",
        "\n",
        "\n",
        "    #\n",
        "\n",
        "    print(train_size, test_size, val_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e13d467-8055-481a-8f53-5d0d25d00752",
      "metadata": {
        "id": "1e13d467-8055-481a-8f53-5d0d25d00752"
      },
      "source": [
        "# Prepare Data\n",
        "The true maps should be appended to the end of the contaminated map array elements. Maybe do this earlier when loading from data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ca058910-36bc-4c3c-a6d2-96ca003c79aa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca058910-36bc-4c3c-a6d2-96ca003c79aa",
        "outputId": "1ae0fc13-d171-4345-b379-5b325fc3ead1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2000, 4, 128, 128)\n"
          ]
        }
      ],
      "source": [
        "print(images.shape)\n",
        "\n",
        "ims = images[:,0:1,:,:].astype(np.float32)\n",
        "targs = images[:,1:2,:,:].astype(np.float32)\n",
        "latlon = images[:,2:, :, :].astype(np.float32)\n",
        "\n",
        "\n",
        "#scale data\n",
        "ims_scale = np.max(ims) - np.min(ims)\n",
        "ims = (ims - np.min(ims)) / ims_scale\n",
        "targs_scale = np.max(targs) - np.min(targs)\n",
        "targs = (targs - np.min(targs)) / targs_scale\n",
        "\n",
        "latlon_1_scale = np.max(latlon[:,0,:,:]) - np.min(latlon[:,0,:,:])\n",
        "latlon_2_scale = np.max(latlon[:,1,:,:]) - np.min(latlon[:,1,:,:])\n",
        "\n",
        "latlon[:,0,:,:] = (latlon[:,0,:,:] - np.min(latlon[:,0,:,:])) / latlon_1_scale\n",
        "latlon[:,1,:,:] = (latlon[:,1,:,:] - np.min(latlon[:,1,:,:])) / latlon_2_scale\n",
        "\n",
        "#lat and lon maps get put on both the targets and the inputs\n",
        "ims = np.concatenate((ims,latlon), axis = 1)\n",
        "targs = np.concatenate((targs, latlon), axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "c3d4c20c-a309-4999-87cf-db45e6bda27a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3d4c20c-a309-4999-87cf-db45e6bda27a",
        "outputId": "3f569ec2-76a0-4805-8c09-8a74944b5dac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training data\n",
            "Dataset\n",
            "  shape of x: torch.Size([384, 3, 128, 128])\n",
            "  shape of y: torch.Size([384, 3, 128, 128])\n",
            "\n",
            "training data for validation\n",
            "Dataset\n",
            "  shape of x: torch.Size([1591, 3, 128, 128])\n",
            "  shape of y: torch.Size([1591, 3, 128, 128])\n",
            "\n",
            "validation data\n",
            "Dataset\n",
            "  shape of x: torch.Size([1591, 3, 128, 128])\n",
            "  shape of y: torch.Size([1591, 3, 128, 128])\n",
            "\n",
            "test data\n",
            "Dataset\n",
            "  shape of x: torch.Size([25, 3, 128, 128])\n",
            "  shape of y: torch.Size([25, 3, 128, 128])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import importlib\n",
        "importlib.reload(dat)\n",
        "\n",
        "train_size = config('train_size')\n",
        "val_size = config('val_size')\n",
        "test_size = config('test_size')\n",
        "\n",
        "#define datasets\n",
        "print('training data')\n",
        "train_data = dat.Dataset(ims, start=0, end=train_size,targets=targs,verbose=True)\n",
        "\n",
        "print('training data for validation')\n",
        "train_data_val = dat.Dataset(ims, start=0, end=train_size, targets=targs, random_sample_size=val_size)\n",
        "\n",
        "print('validation data')\n",
        "val_data = dat.Dataset(ims, start=train_size, end=train_size+val_size, targets=targs)\n",
        "\n",
        "print('test data')\n",
        "test_data = dat.Dataset(ims, start = train_size + val_size, end=train_size + val_size + test_size, targets=targs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c33d5a1c-3c10-4ccd-b7f5-49c7cf1e389b",
      "metadata": {
        "id": "c33d5a1c-3c10-4ccd-b7f5-49c7cf1e389b"
      },
      "source": [
        "# DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "70d98d63-3262-4f83-a9fa-b574857de797",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70d98d63-3262-4f83-a9fa-b574857de797",
        "outputId": "d162b326-c716-4741-e2cb-46a1d6d10924"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data loader\n",
            "train data loader for validation\n",
            "validation data loader\n",
            "test data loader\n"
          ]
        }
      ],
      "source": [
        "import torch.utils.data as dt\n",
        "print('train data loader')\n",
        "train_loader = dt.DataLoader(train_data,\n",
        "                             batch_size=config('batch_size'),\n",
        "                             shuffle=True)\n",
        "\n",
        "print('train data loader for validation')\n",
        "train_loader_val = dt.DataLoader(train_data_val,\n",
        "                                 batch_size=len(train_data_val))\n",
        "\n",
        "print('validation data loader')\n",
        "val_loader  = dt.DataLoader(val_data,\n",
        "                            batch_size=len(val_data))\n",
        "\n",
        "print('test data loader')\n",
        "test_loader = dt.DataLoader(test_data,\n",
        "                            batch_size=len(test_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e40db893-23a5-4b70-b0bb-5c745a7a7046",
      "metadata": {
        "id": "e40db893-23a5-4b70-b0bb-5c745a7a7046"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "192980b0-f029-44a7-8890-e9ede43fbc75",
      "metadata": {
        "id": "192980b0-f029-44a7-8890-e9ede43fbc75"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, padding = 1, dropout = 0.04):\n",
        "        super().__init__()\n",
        "        kernel_size = 2*padding + 1 #3x3 for all convolutions for now\n",
        "        self.conv = nn.Conv2d(in_channels = in_channels, out_channels = out_channels, kernel_size=kernel_size, stride=1, padding = padding, padding_mode='circular')\n",
        "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        #currently not doing any downsampling\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.batchnorm(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "class DilConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dilation = 2, padding = 1, dropout = 0.04):\n",
        "        super().__init__()\n",
        "        kernel_size = 2*padding + 1\n",
        "        self.dconv = nn.Conv2d(in_channels = in_channels, out_channels = out_channels, kernel_size = kernel_size, stride = 1, padding = padding, dilation = dilation, padding_mode = 'circular')\n",
        "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dconv(x)\n",
        "        x = self.batchnorm(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "class ForegroundCleaner(mlp.Model):\n",
        "    def __init__(self, image_size=128, channels=(3,9,14,9,3), padding = 1):\n",
        "        super().__init__()\n",
        "\n",
        "        nlayers = len(channels) - 1\n",
        "\n",
        "\n",
        "        layers = [ConvBlock(channels[i], channels[i+1], padding) for i in range(nlayers)]\n",
        "\n",
        "        #no additional layers for now as the final layer is a convolution\n",
        "        #first set of layers with only convolution blocks\n",
        "        self.layers1 = nn.ModuleList(layers)\n",
        "\n",
        "        #second set of layers which will include dilated convolution\n",
        "        layers2 = []\n",
        "\n",
        "        #alternate between convolution and dilated convolution blocks\n",
        "        for i in range(nlayers):\n",
        "            if i % 2 == 0:\n",
        "                layers2.append(DilConvBlock(channels[i], channels[i+1], 1))\n",
        "            else:\n",
        "                layers2.append(ConvBlock(channels[i], channels[i+1]))\n",
        "\n",
        "        self.layers2 = nn.ModuleList(layers2)\n",
        "\n",
        "        #third set of layers which takes the input maps, downsamples, and passes through convolution\n",
        "        #the goal is to emphasize the large scale structure\n",
        "\n",
        "        layers3 = []\n",
        "\n",
        "        layers3.append(nn.AvgPool2d(kernel_size=4)) #4x4 kernel size in the downsampling\n",
        "        layers3.append(ConvBlock(3,6))\n",
        "        layers3.append(ConvBlock(6,9))\n",
        "        layers3.append(ConvBlock(9,6))\n",
        "        layers3.append(ConvBlock(6,3))\n",
        "        layers3.append(nn.Upsample(scale_factor=4, mode='nearest'))\n",
        "\n",
        "        self.layers3 = nn.ModuleList(layers3)\n",
        "\n",
        "        #The final convolution block to convolute the output from each of the branches\n",
        "        self.final_layer = nn.Conv2d(in_channels=9, out_channels=3, kernel_size=3, padding=1, stride=1, padding_mode='circular')\n",
        "\n",
        "    def forward(self,x):\n",
        "        x1 = x\n",
        "        x2 = x\n",
        "        x3 = x\n",
        "        for layer in self.layers1:\n",
        "            x1 = layer(x1)\n",
        "        for layer in self.layers2:\n",
        "            x2 = layer(x2)\n",
        "        for layer in self.layers3:\n",
        "            x3 = layer(x3)\n",
        "        #concatenate together the results from each branch\n",
        "        x = torch.cat((x1, x2, x3), dim = 1)\n",
        "        #and now pass through colvolution\n",
        "        x = self.final_layer(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "959e687e-caf3-43b7-93dd-84eaa1a5e72c",
      "metadata": {
        "id": "959e687e-caf3-43b7-93dd-84eaa1a5e72c"
      },
      "source": [
        "# Instantiate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "d303c096-3b90-47b0-add4-81b39ad495f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d303c096-3b90-47b0-add4-81b39ad495f6",
        "outputId": "ad30bbe6-6b6c-442d-de67-f85077a89f22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ForegroundCleaner(\n",
            "  (layers1): ModuleList(\n",
            "    (0): ConvBlock(\n",
            "      (conv): Conv2d(3, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
            "      (batchnorm): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU()\n",
            "      (dropout): Dropout(p=0.04, inplace=False)\n",
            "    )\n",
            "    (1): ConvBlock(\n",
            "      (conv): Conv2d(9, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
            "      (batchnorm): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU()\n",
            "      (dropout): Dropout(p=0.04, inplace=False)\n",
            "    )\n",
            "    (2): ConvBlock(\n",
            "      (conv): Conv2d(14, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
            "      (batchnorm): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU()\n",
            "      (dropout): Dropout(p=0.04, inplace=False)\n",
            "    )\n",
            "    (3): ConvBlock(\n",
            "      (conv): Conv2d(9, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
            "      (batchnorm): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU()\n",
            "      (dropout): Dropout(p=0.04, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (layers2): ModuleList(\n",
            "    (0): DilConvBlock(\n",
            "      (dconv): Conv2d(3, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
            "      (batchnorm): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU()\n",
            "      (dropout): Dropout(p=0.04, inplace=False)\n",
            "    )\n",
            "    (1): ConvBlock(\n",
            "      (conv): Conv2d(9, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
            "      (batchnorm): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU()\n",
            "      (dropout): Dropout(p=0.04, inplace=False)\n",
            "    )\n",
            "    (2): DilConvBlock(\n",
            "      (dconv): Conv2d(14, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
            "      (batchnorm): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU()\n",
            "      (dropout): Dropout(p=0.04, inplace=False)\n",
            "    )\n",
            "    (3): ConvBlock(\n",
            "      (conv): Conv2d(9, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
            "      (batchnorm): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU()\n",
            "      (dropout): Dropout(p=0.04, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (layers3): ModuleList(\n",
            "    (0): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
            "    (1): ConvBlock(\n",
            "      (conv): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
            "      (batchnorm): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU()\n",
            "      (dropout): Dropout(p=0.04, inplace=False)\n",
            "    )\n",
            "    (2): ConvBlock(\n",
            "      (conv): Conv2d(6, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
            "      (batchnorm): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU()\n",
            "      (dropout): Dropout(p=0.04, inplace=False)\n",
            "    )\n",
            "    (3): ConvBlock(\n",
            "      (conv): Conv2d(9, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
            "      (batchnorm): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU()\n",
            "      (dropout): Dropout(p=0.04, inplace=False)\n",
            "    )\n",
            "    (4): ConvBlock(\n",
            "      (conv): Conv2d(6, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
            "      (batchnorm): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU()\n",
            "      (dropout): Dropout(p=0.04, inplace=False)\n",
            "    )\n",
            "    (5): Upsample(scale_factor=4.0, mode='nearest')\n",
            "  )\n",
            "  (final_layer): Conv2d(9, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
            ")\n",
            "\n",
            "number of parameters 7332\n",
            "\n"
          ]
        }
      ],
      "source": [
        "importlib.reload(mlp)\n",
        "\n",
        "model = ForegroundCleaner().to(DEVICE)\n",
        "print(model)\n",
        "print()\n",
        "\n",
        "print('number of parameters', mlp.number_of_parameters(model))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45a83ea4-bb8b-45cd-880f-2ffea8670f79",
      "metadata": {
        "id": "45a83ea4-bb8b-45cd-880f-2ffea8670f79"
      },
      "source": [
        "# Loss Function\n",
        "The loss function will have 3 parts, and will be of the form:\n",
        "$$L = \\alpha{L_1} + \\beta{L_2} + \\gamma{L_3}$$\n",
        "The first term will compare the output map to the input map directly. It will use the mean absolute error, or L1 loss function between the output map and the target map:\n",
        "$$L_1 = \\frac{1}{N}\\sum_{n=0}^{N-1}(\\frac{1}{XY}\\sum_{i=0}^{X-1}\\sum_{j=0}^{Y-1}|y^n_{ij} - y'^{n}_{ij}|)$$\n",
        "Where $N$ is the batch size, $X$ is the image size in the x direction, and $Y$ is the image size in the y direction. $y$ is the output map and $y'$ is the target map.\n",
        "The second term is also a L1 loss function, but it will compare the difference between the maps in Fourier space:\n",
        "$$L_2 = \\frac{1}{N}\\sum_{n=0}^{N-1}(\\frac{1}{XY}\\sum_{i = 0}^{X-1}\\sum_{j=0}^{Y-1}|A(\\tilde{y})^n_{ij} - A(\\tilde{y}')^n_{ij}|)$$\n",
        "Where $\\tilde{y}$ the Fourier transform of the input map and $\\tilde{y}'$ is the Fourier transform of the target map. The $A()$ function represents taking the amplitude of the Fourier Transform.\n",
        "The last term will be the quadratic loss between the position maps:\n",
        "$$\n",
        "L_3 = \\frac{1}{N}\\sum_{n=0}^{N-1}(\\frac{1}{2XY}\\sum_{i=0}^{X - 1}\\sum_{j=0}^{Y-1}\\sum_{k=0}^{1}(y^n_{ijk} - y'^n_{ijk})^2)\n",
        "$$  \n",
        "\n",
        "Here the index $k$ indicates whether the latitude or longitude map is being used. The terms are then summed together and as previously mention will be of the form:\n",
        "$$\n",
        "L = \\alpha{L_1} + \\beta{L_2} + \\gamma{L_3}\n",
        "$$\n",
        "Where $\\alpha$, $\\beta$, and $\\gamma$ are constants set such that each term has the same order magnitude impact on the overall loss function, to avoid one term being overemphasized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "66890378-4720-444b-88a4-741b20b3bf4d",
      "metadata": {
        "id": "66890378-4720-444b-88a4-741b20b3bf4d"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import sys\n",
        "class LossFunction():\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, outputs, targets):\n",
        "        #outputs is the maps coming out of the final convolution block, shape (batch_size, 3, size, size)\n",
        "        #targets is the same as before, the maps with no foreground contaminants (batch_size, 3, size, size)\n",
        "        #3 terms summed together give the loss function\n",
        "\n",
        "        #First term: The mean absolute difference between the output map and the target map\n",
        "        #sum across image in batch, image pixels, and across frequency using only I maps for now\n",
        "\n",
        "        #Take the means of the absolute difference across a single image in x and y (exclude lat and lon channels)\n",
        "        #if the mean absolute difference of position channels is used, the whol outputs and targets just get included here\n",
        "        #and the L_3 term can be commented out.\n",
        "        #L_1 = torch.mean(torch.abs(outputs[:,:1,:,:] - targets[:,:1,:,:]) / torch.max(torch.abs(outputs[:,:1,:,:] - targets[:,:1,:,:])))\n",
        "        L_1 = torch.mean(torch.abs(outputs[:,:1,:,:] - targets[:,:1,:,:]))\n",
        "\n",
        "        #Second term: The mean absolute difference between the amplitudes of the Fourier transforms of the output and target maps\n",
        "        #First get the amplitudes of the Fourier transforms\n",
        "\n",
        "        L_2_arr = np.zeros((len(outputs[:,0,0,0]), len(outputs[0,:,0,0]))) #Fill as we go\n",
        "\n",
        "        for i in range(len(outputs[:,0,0,0])): #loop over batch size\n",
        "            for j in range(len(outputs[0,:,0,0]) - 2): #loop over frequencies (exclude the position channels)\n",
        "                #Take the 2D FFT of both the outputs and targets\n",
        "                FFT_output = torch.fft.fft2(outputs[i,j,:,:])\n",
        "                FFT_target = torch.fft.fft2(targets[i,j,:,:])\n",
        "                #Get the amplitudes of the FFTs\n",
        "                A_output = torch.sqrt(FFT_output.real**2 + FFT_output.imag**2)\n",
        "                A_target = torch.sqrt(FFT_target.real**2 + FFT_target.imag**2)\n",
        "                #Get the mean of the absolute value difference of the amplitudes across each FFT map\n",
        "                #ans = torch.mean(torch.abs(A_output - A_target) / torch.max(torch.abs(A_target - A_output)))\n",
        "                ans = torch.mean(torch.abs(A_output - A_target))\n",
        "                #Assign to appropriate place in array\n",
        "                L_2_arr[i,j] = ans\n",
        "        #Now do the average across batch size\n",
        "        L_2 = np.mean(L_2_arr)\n",
        "\n",
        "        #Third term: The mean square difference between the position maps. The aim is to make the model reconstruct the position maps on the sky\n",
        "        #so that the model \"knows\" where it is on the sky.\n",
        "        #average over x and y the square difference in lat and lon\n",
        "        #L_3 = torch.mean((outputs[:,1:,:,:] - targets[:,1:,:,:])**2 / torch.max((outputs[:,1:,:,:] - targets[:,1:,:,:])**2))\n",
        "        L_3 = torch.mean((outputs[:,1:,:,:] - targets[:,1:,:,:])**2)\n",
        "\n",
        "        #coefficients in final loss function were determined by trial and error until each term was\n",
        "        #approximately the same, so that each term has equal weight in the final loss function\n",
        "        alpha = 1\n",
        "        beta = 1/20\n",
        "        gamma = 2\n",
        "\n",
        "        L = alpha*L_1 + beta*L_2 + gamma*L_3\n",
        "\n",
        "\n",
        "        return L"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9fe396f-ed25-4081-b8ab-f266b7d67de4",
      "metadata": {
        "id": "f9fe396f-ed25-4081-b8ab-f266b7d67de4"
      },
      "source": [
        "# Instatiate Training Objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "e46677eb-fa4d-4f55-8f7e-3ec98ed53408",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e46677eb-fa4d-4f55-8f7e-3ec98ed53408",
        "outputId": "b8db32f5-d5ef-47ff-9d01-43ace0d58e29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of milestones:          3\n",
            "\n",
            "Step | Milestone | LR\n",
            "-----------------------------\n",
            "   0 |         0 | 1.0e-03   \n",
            "-----------------------------\n",
            "   1 |     24000 | 8.0e-04   \n",
            "   2 |     48000 | 6.4e-04   \n",
            "   3 |     72000 | 5.1e-04   \n",
            "\n",
            "number of iterations:          96000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=config('base_lr'))\n",
        "scheduler = mlp.get_steplr_scheduler(optimizer, config)\n",
        "objective = mlp.Objective(model, LossFunction())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf6ce16c-5a15-4452-b930-0857eec43397",
      "metadata": {
        "id": "bf6ce16c-5a15-4452-b930-0857eec43397"
      },
      "source": [
        "# Define Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "5c56a0bb-f446-4820-9fd5-1b636a1d8e0b",
      "metadata": {
        "id": "5c56a0bb-f446-4820-9fd5-1b636a1d8e0b"
      },
      "outputs": [],
      "source": [
        "def train(objective, optimizer, scheduler,\n",
        "          train_loader, train_small_loader, val_loader,\n",
        "          config):\n",
        "\n",
        "    # get configuration info\n",
        "    lossfile   = config('file/losses')\n",
        "    paramsfile = config('file/params')\n",
        "    step       = config('monitor_step')\n",
        "    delete     = config('delete')\n",
        "    frac       = config('frac')\n",
        "    nepochs    = config('n_epochs')\n",
        "    niters     = config('n_iterations')\n",
        "\n",
        "    # instantiate object that saves average losses to\n",
        "    # a csv file for realtime monitoring\n",
        "\n",
        "    losswriter = mon.LossWriter(niters,\n",
        "                                lossfile,\n",
        "                                step=step,\n",
        "                                delete=delete,\n",
        "                                frac=frac,\n",
        "                                model=objective.model,\n",
        "                                paramsfile=paramsfile)\n",
        "\n",
        "    # instantiate learning rate step scheduler\n",
        "    lrscheduler = mlp.LRStepScheduler(optimizer, scheduler)\n",
        "\n",
        "    # -----------------------------\n",
        "    # training loop\n",
        "    # -----------------------------\n",
        "    ii = -1\n",
        "    for epoch in range(nepochs):\n",
        "\n",
        "        for x, y in train_loader:\n",
        "\n",
        "            ii += 1\n",
        "\n",
        "            # set mode to training so that training-specific\n",
        "            # operations such as dropout, etc., are enabled.\n",
        "            objective.train()\n",
        "\n",
        "            # clear all gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # compute empirical risk\n",
        "            R = objective(x, y)\n",
        "\n",
        "            # compute gradients\n",
        "            R.backward()\n",
        "\n",
        "            # take one step downhill in the empirical risk landscape\n",
        "            optimizer.step()\n",
        "\n",
        "            # check whether to update learning rate\n",
        "            lrscheduler.step()\n",
        "\n",
        "            # I'm alive printout\n",
        "            if (ii % step == 0) or (ii == niters-1):\n",
        "                with torch.no_grad(): #the no_grad is here to save memory, otherwise I was running out\n",
        "                    # compute average losses on training and validation data\n",
        "                    t_loss = mlp.compute_avg_loss(objective, train_small_loader)\n",
        "                    v_loss = mlp.compute_avg_loss(objective, val_loader)\n",
        "\n",
        "                # return current learning rate\n",
        "                lr = lrscheduler.lr()\n",
        "\n",
        "                # update loss file\n",
        "                losswriter(ii, t_loss, v_loss, lr, epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "b3d3d2e1-b74c-44e8-9b7b-318b0bd6a2b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "b3d3d2e1-b74c-44e8-9b7b-318b0bd6a2b1",
        "outputId": "8bf61651-8ab4-4566-fe52-63ebc639741f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "cannot access local variable 'L_2' where it is not associated with a value",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1400419916.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m train(objective, optimizer, scheduler,\n\u001b[0m\u001b[1;32m      5\u001b[0m       \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       config)\n",
            "\u001b[0;32m/tmp/ipython-input-2644336701.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(objective, optimizer, scheduler, train_loader, train_small_loader, val_loader, config)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;31m# compute empirical risk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;31m# compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/mlinphysics/nn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-4119685513.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, outputs, targets)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mL_2_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m#Now do the average across batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mL_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m#Third term: The mean square difference between the position maps. The aim is to make the model reconstruct the position maps on the sky\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'L_2' where it is not associated with a value"
          ]
        }
      ],
      "source": [
        "importlib.reload(mlp)\n",
        "importlib.reload(mon)\n",
        "\n",
        "train(objective, optimizer, scheduler,\n",
        "      train_loader, train_loader_val, val_loader,\n",
        "      config)\n",
        "\n",
        "monitor = mon.Monitor(config('file/losses'))\n",
        "monitor.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8d9ee8f-43be-4781-9bd7-ab3f6d29d60f",
      "metadata": {
        "id": "c8d9ee8f-43be-4781-9bd7-ab3f6d29d60f"
      },
      "source": [
        "# Visualization of Testing Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9167046d",
      "metadata": {
        "id": "9167046d"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "model.load(config('files/params'))\n",
        "#model.load(\"runs/2025-11-23_1557/foregrounds_params.pth\")\n",
        "test_x, test_y = next(iter(test_loader))\n",
        "y_pred = model(test_x)\n",
        "for i in range(test_size):\n",
        "    index = 0 #Set this to 0 for polarization plot, 1 for lon, 2 for lat\n",
        "    plot_test_y = test_y[i,index,:,:]\n",
        "    plot_pred_y = y_pred[i,index,:,:]\n",
        "    plot_in_map = test_x[i,index,:,:]\n",
        "\n",
        "    fig, ax = plt.subplots(2,2)\n",
        "\n",
        "    im0 = ax[0].imshow(plot_pred_y.cpu().detach().numpy(), vmin = torch.min(plot_test_y), vmax = torch.max(plot_test_y))\n",
        "    ax[0].set_title(\"Predicted Output\")\n",
        "\n",
        "    im1 = ax[1].imshow(plot_test_y.cpu().detach().numpy(), vmin = torch.min(plot_test_y), vmax = torch.max(plot_test_y))\n",
        "    ax[1].set_title(\"Actual Output\")\n",
        "\n",
        "    im2 = ax[2].imshow(plot_in_map.cpu().detach().numpy(), vmin = torch.min(plot_test_y), vmax = torch.max(plot_test_y))\n",
        "    ax[2].set_title(\"Input Map\")\n",
        "\n",
        "    divider0 = make_axes_locatable(ax[0])\n",
        "    cax = divider0.append_axes('right', size = '5%', pad = 0.05)\n",
        "    fig.colorbar(im1, cax = cax)\n",
        "\n",
        "    divider1 = make_axes_locatable(ax[1])\n",
        "    cax = divider1.append_axes('right', size = '5%', pad = 0.05)\n",
        "    fig.colorbar(im1, cax = cax)\n",
        "\n",
        "    divider2 = make_axes_locatable(ax[2])\n",
        "    cax = divider2.append_axes('right', size = '5%', pad = 0.05)\n",
        "    fig.colorbar(im1, cax = cax)\n",
        "\n",
        "    #The last plot is a histogram of the predicted map vs the actual map\n",
        "    #Ideally, the plot should line up along a line with the slope m = 1\n",
        "\n",
        "    hist, x_edge, y_edge = np.histogram2d(plot_test_y.cpu().detach().numpy().flatten(), plot_pred_y.cpu().detach().numpy().flatten(),bins = 1000)\n",
        "    #set empty bins to nan so they show up white\n",
        "    hist[hist == 0] = np.nan\n",
        "    #overplot a line with slope 1\n",
        "    x = np.arange(0, len(plot_test_y.cpu().detach().numpy().flatten()))\n",
        "    y = x\n",
        "    ax[3].plot(x,y)\n",
        "    ax[3].imshow(hist)\n",
        "    plt.savefig(\"comp_\" + str(i) + \".png\")\n",
        "    plt.close('all')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}