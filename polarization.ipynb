{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cadbb41-e934-4859-9d8a-f46b51a7dd3c",
   "metadata": {},
   "source": [
    "## CNN Modeling of CMB Foregrounds\n",
    "The goal of this project is to use a Convolutional Neural Network (CNN) to predict the foreground contamination of a Cosmic Microwave Background (CMB) map. The training data will be maps of foreground models created using the Python Sky Model (PySM3). The training data will consist of maps of multiple frequency bands and both Q and U polarization modes and the Temperature mode to make up input channels. The training data will be found by randomly(?) selecting a region on an all-sky map, and convoluting together pixels in the selected region and across the frequency/polarization channels. After the model is trained, it will be fed a contaminated CMB map and attempt to get rid of the present foregrounds. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c116d31-63ec-4f03-b7d8-f13bfbd62f3b",
   "metadata": {},
   "source": [
    "# Image Creation \n",
    "The CNN will be trained on square images of all sky projections from the Python Sky Model. These images will have 9 input channels, 3 for polarization (I,Q,U) and 3 for frequency (100 GHz, 217 GHz, 353 GHz). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae376711-7786-492f-9264-a7423a0357ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysm3\n",
    "import pysm3.units as u \n",
    "import healpy as hp\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import torch\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def make_foreground_maps(frequencies, strings, nside): \n",
    "    sky = pysm3.Sky(nside = nside, preset_strings=strings + [\"c1\"])\n",
    "    sky_true = pysm3.Sky(nside = nside, preset_strings = [\"c1\"]) \n",
    "    for frequency in frequencies: \n",
    "        skymap = sky.get_emission(frequency*u.GHz) \n",
    "        skymap = skymap.to(u.uK_CMB, equivalencies=u.cmb_equivalencies(frequency*u.GHz))\n",
    "        skymap_true = sky_true.get_emission(frequency*u.GHz)\n",
    "        skymap_true = skymap_true.to(u.uK_CMB, equivalencies=u.cmb_equivalencies(frequency*u.GHz))\n",
    "        hp.fitsfunc.write_map(str(frequency) + \"GHz\", skymap, overwrite=True)\n",
    "        hp.fitsfunc.write_map(str(frequency) + \"GHz_true\", skymap_true, overwrite=True)\n",
    "        \n",
    "\n",
    "def make_images(num, res): \n",
    "    #this function randomly selects a patch on the sky to use as training data. (is this a good idea? I want the position to have some impact on parameters of the model) \n",
    "    #it should get a random selection, then get that section from all of the frequency bands and polarizations.\n",
    "    #num is the number of images \n",
    "    #res is the resolution of the image in arcminutes\n",
    "\n",
    "    #loading all sky projections \n",
    "    map_100 = hp.fitsfunc.read_map(\"100GHz\", field = (0,1,2))\n",
    "    map_217 = hp.fitsfunc.read_map(\"217GHz\", field = (0,1,2))\n",
    "    map_353 = hp.fitsfunc.read_map(\"353GHz\", field = (0,1,2))\n",
    "\n",
    "    map_100_true = hp.fitsfunc.read_map(\"100GHz_true\", field = (0,1,2))\n",
    "    map_217_true = hp.fitsfunc.read_map(\"217GHz_true\", field = (0,1,2))\n",
    "    map_353_true = hp.fitsfunc.read_map(\"353GHz_true\", field = (0,1,2))\n",
    "\n",
    "    size = 256\n",
    "    image_arr = np.zeros((num, 12, size, size))\n",
    "\n",
    "    for i in range(num): \n",
    "        #random generation of lat lon angles on sky \n",
    "        print(\"generating image \" + str(i))\n",
    "        lon = np.random.random() * 360\n",
    "        lat = np.random.random() * 180 - 90 \n",
    "\n",
    "        #generate I map cuts \n",
    "        I_100_square = hp.gnomview(map_100[0], rot = [lon, lat], reso = res, xsize = 256, return_projected_map=True, no_plot=True)\n",
    "        plt.close('all')\n",
    "        I_217_square = hp.gnomview(map_217[0], rot = [lon, lat], reso = res, xsize = 256, return_projected_map=True, no_plot=True)\n",
    "        plt.close('all')\n",
    "        I_353_square = hp.gnomview(map_353[0], rot = [lon, lat], reso = res, xsize = 256, return_projected_map=True, no_plot=True) \n",
    "        plt.close('all')\n",
    "\n",
    "        #generate Q map cuts \n",
    "        Q_100_square = hp.gnomview(map_100[1], rot = [lon, lat], reso = res, xsize = 256, return_projected_map=True, no_plot=True)\n",
    "        plt.close('all')\n",
    "        Q_217_square = hp.gnomview(map_217[1], rot = [lon, lat], reso = res, xsize = 256, return_projected_map=True, no_plot=True) \n",
    "        plt.close('all')\n",
    "        Q_353_square = hp.gnomview(map_353[1], rot = [lon, lat], reso = res, xsize = 256, return_projected_map=True, no_plot=True)\n",
    "        plt.close('all')\n",
    "\n",
    "        #generate U map cuts\n",
    "        U_100_square = hp.gnomview(map_100[2], rot = [lon, lat], reso = res, xsize = 256, return_projected_map=True, no_plot=True)\n",
    "        plt.close('all')\n",
    "        U_217_square = hp.gnomview(map_217[2], rot = [lon, lat], reso = res, xsize = 256, return_projected_map=True, no_plot=True) \n",
    "        plt.close('all')\n",
    "        U_353_square = hp.gnomview(map_353[2], rot = [lon, lat], reso = res, xsize = 256, return_projected_map=True, no_plot=True) \n",
    "        plt.close('all')\n",
    "        I_100_true = hp.gnomview(map_100_true[0], rot = [lon, lat], reso = res, xsize=256, return_projected_map=True, no_plot = True) \n",
    "        plt.close()\n",
    "        I_217_true = hp.gnomview(map_217_true[0], rot = [lon, lat], reso = res, xsize=256, return_projected_map=True,no_plot=True)\n",
    "        plt.close()\n",
    "        I_353_true = hp.gnomview(map_353_true[0], rot = [lon, lat], reso = res, xsize=256, return_projected_map=True,no_plot=True)\n",
    "        plt.close('all')\n",
    "        \n",
    "        #stack the maps into one 3D array along first axis\n",
    "        image_arr[i] = np.stack((I_100_square, I_217_square, I_353_square, Q_100_square, Q_217_square, Q_353_square, U_100_square, U_217_square, U_353_square, I_100_true, I_217_true, I_353_true))\n",
    "\n",
    "        #save flattened array to text file  \n",
    "\n",
    "        del Q_100_square\n",
    "        del Q_217_square\n",
    "        del Q_353_square\n",
    "        del U_100_square\n",
    "        del U_217_square\n",
    "        del U_353_square\n",
    "        del I_100_square\n",
    "        del I_217_square\n",
    "        del I_353_square\n",
    "        del I_100_true\n",
    "        del I_217_true\n",
    "        del I_353_true\n",
    "\n",
    "    with h5py.File('images.h5', 'w') as hf: \n",
    "        hf.create_dataset('foregrounds_images', data = image_arr)\n",
    "        \n",
    "#generate all sky projections and cuts. This only has to be done once, then can be commented out unless new foreground contaminants or cuts are desired. \n",
    "\n",
    "#make_foreground_maps([100,217,353], [\"s1\", \"d1\"], 512)\n",
    "#make_images(500, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152bea32-a8d0-4f1b-839c-575fb23c3537",
   "metadata": {},
   "source": [
    "# Set Device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a20c4e5a-f91d-4b71-96e6-54b73cfd3f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    print('Running on CoLab')\n",
    "    google.colab.drive.mount(\"/content/gdrive\")\n",
    "    %cd /content/gdrive/MyDrive/MLP\n",
    "    \n",
    "    !git clone --no-checkout https://github.com/hbprosper/mlinphysics.git\n",
    "    !cd mlinphysics\n",
    "    !git sparse-checkout init --cone\n",
    "    !git sparse-checkout __init__ nn.py bin utils\n",
    "    print('\\n\\tdownload complete!\\n')\n",
    "    \n",
    "# standard system modules\n",
    "import os, sys\n",
    "\n",
    "# standard module for tabular data\n",
    "import pandas as pd\n",
    "\n",
    "# standard module for array manipulation\n",
    "import numpy as np\n",
    "\n",
    "# standard module for high-quality plots\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# standard research-level machine learning toolkit from Meta (FKA: FaceBook)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as dt\n",
    "\n",
    "# module to access data in Hierarchical Data Format (HDF or H5 format)\n",
    "import h5py\n",
    "\n",
    "# module to plot pixelized images\n",
    "import imageio.v3 as im\n",
    "\n",
    "# module to reimport Python modules\n",
    "import importlib\n",
    "\n",
    "# module for saving/loading serialized Python objects\n",
    "import joblib\n",
    "\n",
    "# module for shell utilities\n",
    "import shutil\n",
    "\n",
    "# ML in physics module\n",
    "import mlinphysics.nn as mlp\n",
    "import mlinphysics.utils.data as dat\n",
    "import mlinphysics.utils.monitor as mon\n",
    "\n",
    "if not IN_COLAB:\n",
    "    usetex = shutil.which('latex') is not None\n",
    "    plt.rcParams.update({\n",
    "      \"text.usetex\": usetex, \n",
    "      \"font.family\": \"sans-serif\",\n",
    "      \"font.sans-serif\": \"Helvetica\",\n",
    "      \"font.size\": 14\n",
    "  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8defc580-7586-4c63-8fcb-6fea706fe29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tAvailable device: cpu \n",
      "\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'\\n\\tAvailable device: {str(DEVICE):4s}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4682ab0f-748c-4ccf-bff1-3432c775c42e",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network Layout\n",
    "The input shape of the image fed to the network is (9,200,200). The output shape should be (3,200,200) with just Temperature mode output. Going to try a simple 3 level model going to (27, 200, 200) before final step back to (3, 200, 200). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672f6c36-886c-4119-a410-6e3ee749ee15",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f823bf52-4786-4e96-aaa2-20ea118e660a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: foregrounds\n",
      "file:\n",
      "  losses: runs/2025-11-12_0836/foregrounds_losses.csv\n",
      "  params: runs/2025-11-12_0836/foregrounds_params.pth\n",
      "  init_params: runs/2025-11-12_0836/foregrounds_init_params.pth\n",
      "  plots: runs/2025-11-12_0836/foregrounds_plots.png\n",
      "batch_size: 16\n",
      "train_size: 384\n",
      "test_size: 25\n",
      "val_size: 91\n",
      "monitor_step: 10\n",
      "delete: true\n",
      "frac: 0.015\n",
      "n_epochs: 200\n",
      "n_iters_per_epoch: 24\n",
      "n_iterations: 4800\n",
      "n_steps: 4\n",
      "n_iters_per_step: 1200\n",
      "base_lr: 0.01\n",
      "gamma: 0.8\n",
      "\n",
      "384 25 91\n"
     ]
    }
   ],
   "source": [
    "import mlinphysics.nn as mlp\n",
    "import mlinphysics.utils.data as dat \n",
    "import mlinphysics.utils.monitor as mon \n",
    "\n",
    "#load images \n",
    "\n",
    "with h5py.File(\"images.h5\", \"r\") as f: \n",
    "    images = f['foregrounds_images']\n",
    "    images = images[...]   \n",
    "\n",
    "#configure model \n",
    "\n",
    "    name = 'foregrounds' \n",
    "\n",
    "    load_existing_config = False\n",
    "    \n",
    "    if load_existing_config: \n",
    "        config = mlp.Config(f'{name}.yaml')\n",
    "    else: \n",
    "        config = mlp.Config(name)\n",
    "    \n",
    "        #training config\n",
    "        n_images = len(images) \n",
    "        batch_size = 16 \n",
    "        n_iters_per_epoch = 24\n",
    "        train_size = n_iters_per_epoch * batch_size\n",
    "        test_size = 25\n",
    "        val_size = n_images - train_size - test_size\n",
    "    \n",
    "        config('batch_size', batch_size)\n",
    "        config('train_size', train_size)\n",
    "        config('test_size', test_size)\n",
    "        config('val_size', val_size)\n",
    "    \n",
    "        config('monitor_step', 10)\n",
    "        config('delete', True) \n",
    "        config('frac', 0.015)\n",
    "    \n",
    "        #optimizer/scheduler\n",
    "    \n",
    "        config('n_epochs', 200)\n",
    "        config('n_iters_per_epoch', n_iters_per_epoch)\n",
    "        config('n_iterations', config('n_epochs') * config('n_iters_per_epoch'))\n",
    "        config('n_steps', 4)\n",
    "        config('n_iters_per_step', config('n_iterations') // config('n_steps'))\n",
    "        config('base_lr', 1.e-2)\n",
    "        config('gamma', 0.8)\n",
    "    \n",
    "        config.save()\n",
    "    print(config)\n",
    "    \n",
    "\n",
    "    #\n",
    "\n",
    "    print(train_size, test_size, val_size) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e13d467-8055-481a-8f53-5d0d25d00752",
   "metadata": {},
   "source": [
    "# Prepare Data\n",
    "The true maps should be appended to the end of the contaminated map array elements. Maybe do this earlier when loading from data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca058910-36bc-4c3c-a6d2-96ca003c79aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 12, 256, 256)\n",
      "ims is nan  False\n",
      "targs is nan  False\n",
      "float32\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)\n",
    "\n",
    "ims = images[:,0:9,:,:].astype(np.float32)\n",
    "targs = images[:,9:12,:,:].astype(np.float32)\n",
    "\n",
    "print(\"ims is nan \", np.any(np.isnan(ims)))\n",
    "print(\"targs is nan \", np.any(np.isnan(targs)))\n",
    "\n",
    "print(ims.dtype)\n",
    "print(targs.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3d4c20c-a309-4999-87cf-db45e6bda27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data\n",
      "Dataset\n",
      "  shape of x: torch.Size([384, 9, 256, 256])\n",
      "  shape of y: torch.Size([384, 3, 256, 256])\n",
      "\n",
      "training data for validation\n",
      "Dataset\n",
      "  shape of x: torch.Size([91, 9, 256, 256])\n",
      "  shape of y: torch.Size([91, 3, 256, 256])\n",
      "\n",
      "validation data\n",
      "Dataset\n",
      "  shape of x: torch.Size([91, 9, 256, 256])\n",
      "  shape of y: torch.Size([91, 3, 256, 256])\n",
      "\n",
      "test data\n",
      "Dataset\n",
      "  shape of x: torch.Size([25, 9, 256, 256])\n",
      "  shape of y: torch.Size([25, 3, 256, 256])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(dat)\n",
    "\n",
    "train_size = config('train_size')\n",
    "val_size = config('val_size')\n",
    "test_size = config('test_size')\n",
    "\n",
    "#define datasets \n",
    "print('training data') \n",
    "train_data = dat.Dataset(ims, start=0, end=train_size,targets=targs,verbose=True)\n",
    "\n",
    "print('training data for validation') \n",
    "train_data_val = dat.Dataset(ims, start=0, end=train_size, targets=targs, random_sample_size=val_size)\n",
    "\n",
    "print('validation data')\n",
    "val_data = dat.Dataset(ims, start=train_size, end=train_size+val_size, targets=targs)\n",
    "\n",
    "print('test data')\n",
    "test_data = dat.Dataset(ims, start = train_size + val_size, end=train_size + val_size + test_size, targets=targs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33d5a1c-3c10-4ccd-b7f5-49c7cf1e389b",
   "metadata": {},
   "source": [
    "# DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70d98d63-3262-4f83-a9fa-b574857de797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data loader\n",
      "train data loader for validation\n",
      "validation data loader\n",
      "test data loader\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as dt\n",
    "print('train data loader')\n",
    "train_loader = dt.DataLoader(train_data,\n",
    "                             batch_size=config('batch_size'),\n",
    "                             shuffle=True)\n",
    "\n",
    "print('train data loader for validation')\n",
    "train_loader_val = dt.DataLoader(train_data_val,\n",
    "                                 batch_size=len(train_data_val))\n",
    "\n",
    "print('validation data loader')\n",
    "val_loader  = dt.DataLoader(val_data,\n",
    "                            batch_size=len(val_data))\n",
    "\n",
    "print('test data loader')\n",
    "test_loader = dt.DataLoader(test_data,\n",
    "                            batch_size=len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40db893-23a5-4b70-b0bb-5c745a7a7046",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "192980b0-f029-44a7-8890-e9ede43fbc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ConvBlock(nn.Module): \n",
    "    def __init__(self, in_channels, out_channels, padding = 1, dropout = 0.04):\n",
    "        super().__init__()\n",
    "        kernel_size = 2*padding + 1 #3x3 for all convolutions for now \n",
    "        self.conv = nn.Conv2d(in_channels = in_channels, out_channels = out_channels, kernel_size=kernel_size, stride=1, padding = padding, padding_mode='circular')\n",
    "        #self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.LeakyReLU(negative_slope=0.4)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        #currently not doing any downsampling \n",
    "\n",
    "    def forward(self, x): \n",
    "        x = self.conv(x)\n",
    "        #x = self.batchnorm(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        return x \n",
    "\n",
    "class ForegroundCleaner(mlp.Model): \n",
    "    def __init__(self, image_size=256, channels=(9, 18, 27, 18, 3), padding = 1): \n",
    "        super().__init__()\n",
    "\n",
    "        nlayers = len(channels) - 1\n",
    "\n",
    "        #number of inputs into final map layer \n",
    "        #final_image_size = (image_size, image_size)\n",
    "        #ninputs = channels[-1]*image_size**2\n",
    "\n",
    "        layers = [ConvBlock(channels[i], channels[i+1], padding) for i in range(nlayers)]\n",
    "\n",
    "        #no additional layers for now as the final layer is a convolution \n",
    "        self.layers = nn.ModuleList(layers) \n",
    "\n",
    "    def forward(self,x): \n",
    "        for layer in self.layers: \n",
    "            x = layer(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959e687e-caf3-43b7-93dd-84eaa1a5e72c",
   "metadata": {},
   "source": [
    "# Instantiate Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d303c096-3b90-47b0-add4-81b39ad495f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ForegroundCleaner(\n",
      "  (layers): ModuleList(\n",
      "    (0): ConvBlock(\n",
      "      (conv): Conv2d(9, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
      "      (relu): LeakyReLU(negative_slope=0.4)\n",
      "      (dropout): Dropout(p=0.04, inplace=False)\n",
      "    )\n",
      "    (1): ConvBlock(\n",
      "      (conv): Conv2d(18, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
      "      (relu): LeakyReLU(negative_slope=0.4)\n",
      "      (dropout): Dropout(p=0.04, inplace=False)\n",
      "    )\n",
      "    (2): ConvBlock(\n",
      "      (conv): Conv2d(27, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
      "      (relu): LeakyReLU(negative_slope=0.4)\n",
      "      (dropout): Dropout(p=0.04, inplace=False)\n",
      "    )\n",
      "    (3): ConvBlock(\n",
      "      (conv): Conv2d(18, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
      "      (relu): LeakyReLU(negative_slope=0.4)\n",
      "      (dropout): Dropout(p=0.04, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "number of parameters 10758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(mlp) \n",
    "\n",
    "model = ForegroundCleaner().to(DEVICE)\n",
    "print(model)\n",
    "print()\n",
    "\n",
    "print('number of parameters', mlp.number_of_parameters(model)) \n",
    "print() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a83ea4-bb8b-45cd-880f-2ffea8670f79",
   "metadata": {},
   "source": [
    "# Loss Function\n",
    "The loss function will have 3 parts. One part is the mean of the absolute deviation between the input intensity map and the output intensity map. The second is similar but uses the amplitude of the Fourier Transform of the map. The last part will compute and compare the power spectrun between the target and the current map. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66890378-4720-444b-88a4-741b20b3bf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class LossFunction(): \n",
    "\n",
    "    def __init__(self): \n",
    "        pass\n",
    "\n",
    "    def __call__(self, outputs, targets): \n",
    "        #outputs is the maps coming out of the final convolution block, shape (batch_size, 3, 256, 256)\n",
    "        #targets is the same as before, the maps with no foreground contaminants (batch_size, 3, 256, 256)\n",
    "        #3 terms summed together give the loss function \n",
    "\n",
    "        #First term: The mean absolute difference between the output map and the target map \n",
    "        #sum across image in batch, image pixels, and across frequency using only I maps for now \n",
    "\n",
    "        #Take the means of the absolute difference across a single image in x and y\n",
    "        L_1 = torch.mean(torch.abs(outputs - targets) / torch.max(torch.abs(outputs - targets)), dim=(2,3))\n",
    "        #Average across frequencies \n",
    "        L_1 = torch.mean(L_1, dim = 1)\n",
    "        #Average across batch size \n",
    "        L_1 = torch.mean(L_1, dim = 0)\n",
    "\n",
    "        #Second term: The mean absolute difference between the amplitudes of the Fourier transforms of the output and target maps \n",
    "        #First get the amplitudes of the Fourier transforms \n",
    "\n",
    "        L_2 = 0 #Fill as we go \n",
    "\n",
    "        for i in range(len(outputs[:,0,0,0])): #loop over batch size \n",
    "            for j in range(len(outputs[0,:,:])): #loop over frequencies \n",
    "                FFT_output = torch.fft.fft2(outputs[i,j,:,:])\n",
    "                FFT_target = torch.fft.fft2(targets[i,j,:,:])\n",
    "                A_output = torch.sqrt(FFT_output.real**2 + FFT_output.imag**2)\n",
    "                A_target = torch.sqrt(FFT_target.real**2 + FFT_target.imag**2)\n",
    "                ans = torch.mean(torch.abs(A_output - A_target)) / torch.max(torch.abs(A_target - A_output))\n",
    "                if(math.isnan(ans)):\n",
    "                    print(\"FIRE\")\n",
    "                    sys.exit()\n",
    "                L_2 += ans\n",
    "\n",
    "        L = L_1 + L_2\n",
    "                \n",
    "        \n",
    "        return L "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fe396f-ed25-4081-b8ab-f266b7d67de4",
   "metadata": {},
   "source": [
    "# Instatiate Training Objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e46677eb-fa4d-4f55-8f7e-3ec98ed53408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of milestones:          3\n",
      "\n",
      "Step | Milestone | LR\n",
      "-----------------------------\n",
      "   0 |         0 | 1.0e-02   \n",
      "-----------------------------\n",
      "   1 |      1200 | 8.0e-03   \n",
      "   2 |      2400 | 6.4e-03   \n",
      "   3 |      3600 | 5.1e-03   \n",
      "\n",
      "number of iterations:           4800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=config('base_lr'))\n",
    "scheduler = mlp.get_steplr_scheduler(optimizer, config)\n",
    "objective = mlp.Objective(model, LossFunction())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6ce16c-5a15-4452-b930-0857eec43397",
   "metadata": {},
   "source": [
    "# Define Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c56a0bb-f446-4820-9fd5-1b636a1d8e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(objective, optimizer, scheduler,\n",
    "          train_loader, train_small_loader, val_loader,\n",
    "          config):\n",
    "\n",
    "    # get configuration info\n",
    "    lossfile   = config('file/losses')\n",
    "    paramsfile = config('file/params')\n",
    "    step       = config('monitor_step')\n",
    "    delete     = config('delete')\n",
    "    frac       = config('frac')\n",
    "    nepochs    = config('n_epochs')\n",
    "    niters     = config('n_iterations')\n",
    "    \n",
    "    # instantiate object that saves average losses to\n",
    "    # a csv file for realtime monitoring\n",
    "\n",
    "    losswriter = mon.LossWriter(niters,\n",
    "                                lossfile,\n",
    "                                step=step,\n",
    "                                delete=delete,\n",
    "                                frac=frac,\n",
    "                                model=objective.model,\n",
    "                                paramsfile=paramsfile)\n",
    "\n",
    "    # instantiate learning rate step scheduler\n",
    "    lrscheduler = mlp.LRStepScheduler(optimizer, scheduler)\n",
    "\n",
    "    # -----------------------------\n",
    "    # training loop\n",
    "    # -----------------------------\n",
    "    ii = -1\n",
    "    for epoch in range(nepochs):\n",
    "        \n",
    "        for x, y in train_loader:\n",
    "  \n",
    "            ii += 1\n",
    "            \n",
    "            # set mode to training so that training-specific\n",
    "            # operations such as dropout, etc., are enabled.\n",
    "            objective.train()\n",
    "    \n",
    "            # clear all gradients\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # compute empirical risk\n",
    "            R = objective(x, y)\n",
    "    \n",
    "            # compute gradients\n",
    "            R.backward()\n",
    "    \n",
    "            # take one step downhill in the empirical risk landscape\n",
    "            optimizer.step()\n",
    "    \n",
    "            # check whether to update learning rate\n",
    "            lrscheduler.step()\n",
    "    \n",
    "            # I'm alive printout\n",
    "            if (ii % step == 0) or (ii == niters-1):\n",
    "    \n",
    "                # compute average losses on training and validation data\n",
    "                t_loss = mlp.compute_avg_loss(objective, train_small_loader)\n",
    "                v_loss = mlp.compute_avg_loss(objective, val_loader)\n",
    "    \n",
    "                # return current learning rate\n",
    "                lr = lrscheduler.lr()\n",
    "    \n",
    "                # update loss file\n",
    "                losswriter(ii, t_loss, v_loss, lr, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d3d2e1-b74c-44e8-9b7b-318b0bd6a2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\tlearning rate:  1.000e-02\n",
      "       190|  3.98%|00:12:29/05:01:36|   0.3 it/s|         7|6.469e-02|5.909e-02|"
     ]
    }
   ],
   "source": [
    "importlib.reload(mlp)\n",
    "importlib.reload(mon)\n",
    "\n",
    "train(objective, optimizer, scheduler,\n",
    "      train_loader, train_loader_val, val_loader,\n",
    "      config)\n",
    "\n",
    "monitor = mon.Monitor(config('file/losses'))\n",
    "monitor.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d9ee8f-43be-4781-9bd7-ab3f6d29d60f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
